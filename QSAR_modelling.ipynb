{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install QSPRpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/CDDLeiden/QSPRPred.git@BOO-2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching data from Papyrus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SKIP THIS CELL ###\n",
    "\n",
    "from qsprpred.data.sources.papyrus import Papyrus\n",
    "\n",
    "acc_keys = [\"P49840\", \"P36897\", \"Q13464\", \"P22455\", \"P21802\"] # Specify the protein accession key(s) of your target(s) of interest\n",
    "dataset_name = \"papyrus_data\"  # name of the file to be generated\n",
    "quality = \"low\"  # choose minimum quality from {\"high\", \"medium\", \"low\"}\n",
    "papyrus_version = '05.6'  # Papyrus database version\n",
    "data_dir = \"data\"\n",
    "\n",
    "papyrus = Papyrus(\n",
    "    data_dir=data_dir,\n",
    "    version=papyrus_version,\n",
    "    stereo=False,\n",
    "    plus_only=False, # Set to False to include lower quality data\n",
    ")\n",
    "\n",
    "mt = papyrus.getData(\n",
    "    acc_keys,\n",
    "    quality,\n",
    "    name=dataset_name,\n",
    "    use_existing=True,\n",
    "    activity_types=[\"Ki\", \"IC50\", \"Kd\", \"EC50\"]\n",
    ")\n",
    "mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all data\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/papyrus_data.tsv', sep='\\t')\n",
    "\n",
    "# filter data for target of interest\n",
    "MY_TARGET = 'P49840' # REPLACE WITH YOUR TARGET ACCESSION\n",
    "\n",
    "df = df[df['accession'] == MY_TARGET]\n",
    "\n",
    "# keep only high quality data\n",
    "df = df[df['Quality'] == 'High']\n",
    "\n",
    "# Create molecule table for visualization\n",
    "from qsprpred.data.data import MoleculeTable\n",
    "\n",
    "mt = MoleculeTable(df=df, name=MY_TARGET, store_dir='data')\n",
    "\n",
    "mt.getDF()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.models.tasks import TargetTasks\n",
    "from qsprpred.data.data import QSPRDataset\n",
    "\n",
    "target_props=[{\n",
    "                \"name\": \"pchembl_value_Median\", # name of the target column in the dataset\n",
    "                \"task\": TargetTasks.REGRESSION, # specify the task type (SINGLECLASS, MULTICLASS, REGRESSION)\n",
    "                }]\n",
    "\n",
    "# Create a QSPRDataset instance used for training and evaluation of QSPR models\n",
    "dataset = QSPRDataset.fromMolTable(mt, target_props=target_props)\n",
    "dataset.targetProperties"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![descriptors](figures/descriptors.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.data.utils.descriptorsets import FingerprintSet\n",
    "from qsprpred.data.utils.descriptorcalculator import MoleculeDescriptorsCalculator\n",
    "from sklearn.preprocessing import StandardScaler as Scaler\n",
    "from qsprpred.data.utils.datasplitters import randomsplit\n",
    "\n",
    "# Calculate MorganFP and physicochemical properties\n",
    "feature_calculator = MoleculeDescriptorsCalculator(descsets = [FingerprintSet(fingerprint_type=\"MorganFP\", radius=3, nBits=2048)])\n",
    "\n",
    "# Do a random split for creating the train (80%) and test set (20%)\n",
    "rand_split = randomsplit(0.2)\n",
    "\n",
    "# calculate compound features and split dataset into train and test\n",
    "dataset.prepareDataset(\n",
    "    split=rand_split,\n",
    "    feature_calculators=[feature_calculator],\n",
    "    feature_standardizer=Scaler()\n",
    ")\n",
    "\n",
    "print(f\"Number of samples train set: {len(dataset.y)}\")\n",
    "print(f\"Number of samples test set: {len(dataset.y_ind)}\")\n",
    "\n",
    "# Let's save the dataset for later\n",
    "dataset.save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram of pchembl values in the dataset\n",
    "import seaborn as sns\n",
    "sns.histplot(dataset.getDF()['pchembl_value_Median'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the compounds with the highest pchembl values in the dataset\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "# number of compounds to show\n",
    "NUM_COMPOUNDS = 30\n",
    "\n",
    "# Sort the dataset by pchembl value\n",
    "dataset_sorted = dataset.getDF().sort_values(by='pchembl_value_Median', ascending=False)\n",
    " \n",
    "# show average pchembl value per scaffold and the count of compounds per scaffold\n",
    "Draw.MolsToGridImage([MolFromSmiles(smiles) for smiles in dataset_sorted[:NUM_COMPOUNDS].SMILES], molsPerRow=5, subImgSize=(200,200), legends=[f\"{dataset_sorted['pchembl_value_Median'][idx]:.2f}\" for idx in dataset_sorted[:NUM_COMPOUNDS].index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scaffviz.clustering.manifold import TSNE\n",
    "from qsprpred.data.utils.scaffolds import Murcko, BemisMurcko\n",
    "from scaffviz.depiction.plot import Plot\n",
    "\n",
    "# Show top n scaffolds with at least x compounds\n",
    "NUM_SCAFFOLDS = 20\n",
    "MIN_COMPOUNDS = 5\n",
    "\n",
    "dataset.addScaffolds([Murcko()])\n",
    "\n",
    "# get average pchembl value per scaffold\n",
    "scaffolds = dataset.getDF().groupby('Scaffold_Murcko')['pchembl_value_Median'].mean().sort_values(ascending=False)\n",
    "scaffolds = scaffolds.rename('Average pchembl value')\n",
    "\n",
    "# add the number of compounds per scaffold\n",
    "scaffolds = pd.concat([scaffolds, dataset.getDF().groupby('Scaffold_Murcko')['pchembl_value_Median'].count()], axis=1)\n",
    "scaffolds = scaffolds.rename(columns={'pchembl_value_Median': 'Count'})\n",
    "\n",
    "# Drop scaffolds with less than MIN_COMPOUNDS compounds\n",
    "scaffolds = scaffolds[scaffolds['Count'] > MIN_COMPOUNDS]\n",
    " \n",
    "# show average pchembl value per scaffold and the count of compounds per scaffold\n",
    "Draw.MolsToGridImage([MolFromSmiles(scaffold) for scaffold in scaffolds.index[:NUM_SCAFFOLDS]], molsPerRow=5, subImgSize=(200,200), legends=[f\"{scaffolds['Average pchembl value'][scaffold]:.2f} ({scaffolds['Count'][scaffold]})\" for scaffold in scaffolds.index[:NUM_SCAFFOLDS]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all compounds from from scaffold N.\n",
    "\n",
    "SCAFFOLD_INDEX = 0\n",
    "\n",
    "scaffold = scaffolds.index[SCAFFOLD_INDEX]\n",
    "\n",
    "# get all compounds from scaffold\n",
    "scaffold_df = dataset.getDF()[dataset.getDF()['Scaffold_Murcko'] == scaffold]\n",
    "\n",
    "# sort compounds by pchembl value\n",
    "scaffold_df = scaffold_df.sort_values(by='pchembl_value_Median', ascending=False)\n",
    "\n",
    "# visualize compounds\n",
    "Draw.MolsToGridImage([MolFromSmiles(smiles) for smiles in scaffold_df.SMILES], molsPerRow=5, subImgSize=(200,200), legends=[f\"{scaffold_df['pchembl_value_Median'][idx]:.2f}\" for idx in scaffold_df.index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CPU = 4 # number of CPUs for parallel operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.models.models import QSPRsklearn\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from qsprpred.models.hyperparam_optimization import OptunaOptimization\n",
    "\n",
    "# This is an SKlearn model, so we will initialize it with the QSPRsklearn class\n",
    "model = QSPRsklearn(base_dir = '.', data=dataset, alg = PLSRegression, name='PLS_REG')\n",
    "\n",
    "# We will first optimize the hyperparameters (n_components and scale) through bayes optimization\n",
    "# the best hyperparameter combination will be saved in PLS_REG_params.json\n",
    "search_space_bs = {\"n_components\": [\"int\", 1, 30], \"scale\": [\"categorical\", [True, False]]}\n",
    "bayesoptimizer = OptunaOptimization(scoring = model.score_func, param_grid=search_space_bs, n_trials=5)\n",
    "best_params = bayesoptimizer.optimize(model)\n",
    "\n",
    "#Then we will evaluate the performance of the best model using the independent test set\n",
    "_ = model.evaluate()\n",
    "\n",
    "# Finally, we need to fit the model on the complete dataset if we want to use it further\n",
    "# model is saved under qspr/models/PLS_REG.json\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.plotting.regression import CorrelationPlot\n",
    "\n",
    "plt = CorrelationPlot([model])\n",
    "axes, summary = plt.make(save=False, property_name='pchembl_value_Median')\n",
    "axes[0]\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions for your own compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your own compounds\n",
    "list_of_smiles = ['OCCc1ccn2cnccc12',\n",
    "                  'C1CC1Oc1cc2ccncn2c1',\n",
    "                  'CNC(=O)c1nccc2cccn12'] # REPLACE WITH YOUR OWN COMPOUNDS\n",
    "\n",
    "# make predictions with the model\n",
    "predictions = model.predictMols(list_of_smiles)\n",
    "\n",
    "# show molecules with predicted values using rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    " \n",
    "mols = [Chem.MolFromSmiles(smi) for smi in list_of_smiles]\n",
    "Draw.MolsToGridImage(mols, molsPerRow=4, subImgSize=(200, 200), legends=[f'{pred[0]:.3f}' for pred in predictions])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ulla2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
